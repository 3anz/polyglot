{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_dir = \"/media/data/code/polyglot/\"\n",
    "\n",
    "if exp_dir not in sys.path:\n",
    "  sys.path.insert(0, exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import polyglot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Languages Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were trained on a combination of:\n",
    "- Original CONLL datasets after the tags were converted using the [universal POS tables](http://universaldependencies.github.io/docs/tagset-conversion/index.html).\n",
    "- Universal Dependencies 1.0 corpora whenever they are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afrikaans, Albanian, Alemannic, Amharic, Arabic, Aragonese, Armenian, Assamese, Asturian, Azerbaijani, Bashkir, Basque, Bavarian, Belarusian, Bengali, Bishnupriya Manipuri, Bosnian, Bosnian-Croatian-Serbian, Breton, Bulgarian, Burmese, Catalan; Valencian, Cebuano, Chechen, Chinese, Chuvash, Croatian, Czech, Danish, Divehi; Dhivehi; Maldivian;, Dutch, Egyptian Arabic, English, Esperanto, Estonian, Faroese, Fiji Hindi, Finnish, French, Galician, Gan Chinese, Georgian, German, Greek, Modern, Gujarati, Haitian; Haitian Creole, Hebrew (modern), Hindi, Hungarian, Icelandic, Ido, Ilokano, Indonesian, Interlingua, Irish, Italian, Japanese, Javanese, Kannada, Kapampangan, Kazakh, Khmer, Kirghiz, Kyrgyz, Korean, Kurdish, Latin, Latvian, Limburgish, Limburgan, Limburger, Lithuanian, Lombard language, Luxembourgish, Letzeburgesch, Macedonian, Malagasy, Malay, Malayalam, Maltese, Manx, Marathi (Marāṭhī), Mongolian, Nepali, Northern Sami, Norwegian, Norwegian Nynorsk, Occitan, Oriya, Ossetian, Ossetic, Panjabi, Punjabi, Pashto, Pushto, Persian, Piedmontese language, Polish, Portuguese, Quechua, Romanian, Moldavian, Moldovan, Romansh, Russian, Sakha, Sanskrit (Saṁskṛta), Scots, Scottish Gaelic; Gaelic, Serbian, Sicilian, Silesian, Sinhala, Sinhalese, Slovak, Slovene, Spanish; Castilian, Sundanese, Swahili, Swedish, Tagalog, Tajik, Tamil, Tatar, Telugu, Thai, Tibetan Standard, Tibetan, Central, Turkish, Turkmen, Uighur, Uyghur, Ukrainian, Upper Sorbian, Urdu, Uzbek, Venetian, Vietnamese, Volapük, Walloon, Waray-Waray, Welsh, West Flemish, Western Frisian, Yiddish, Yoruba, Zazaki\n"
     ]
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "print(\", \".join(sorted(downloader.supported_languages(\"morph2\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Necessary Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package morph2.en to\n",
      "[polyglot_data]     /home/rmyeid/polyglot_data...\n",
      "[polyglot_data]   Package morph2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package morph2.ar to\n",
      "[polyglot_data]     /home/rmyeid/polyglot_data...\n",
      "[polyglot_data]   Package morph2.ar is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "polyglot download morph2.en morph2.ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tag each word in the text with one part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from polyglot.text import Text, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blob = \"Wewillmeettoday.\"\n",
    "text = Text(blob)\n",
    "text.language = \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query all the tagged words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([u'We', u'will', u'meet', u'to', u'day', u'.'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.morphemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calling the pos_tags property once, the words objects will carry the POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing       ['pre', 'process', 'ing']\n",
      "processor           ['process', 'or']\n",
      "invaluable          ['in', 'valuable']\n",
      "thankful            ['thank', 'ful']\n",
      "crossed             ['cross', 'ed']\n"
     ]
    }
   ],
   "source": [
    "words = [\"preprocessing\", \"processor\", \"invaluable\", \"thankful\", \"crossed\"]\n",
    "for w in words:\n",
    "  w2 = Word(w, language=\"en\")\n",
    "  print(\"{:<20}{}\".format(w2, w2.morphemes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "\n",
    "Notice, if we do not pass `--lang` the language code, the detector will bem used to detect the language of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia posted a World Cup record total of 417 - 6 as they beat Afghanistan by 275 runs .\n",
      "David Warner hit 178 off 133 balls , Steve Smith scored 95 while Glenn Maxwell struck 88 in 39 deliveries in the Pool A encounter in Perth .\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tok_file=/tmp/cricket.tok.txt\n",
    "polyglot --lang en tokenize --input testdata/cricket.txt > $tok_file\n",
    "head -n 2 $tok_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-               -    \n",
      "4               4    \n",
      "against         a_gain_st\n",
      "West            West \n",
      "Indies          In_dies\n",
      "and             and  \n",
      "Ireland         Ireland\n",
      "respectively    re_spective_ly\n",
      ".               .    \n",
      "\n",
      "The             The  \n",
      "winning         winning\n",
      "margin          margin\n",
      "beats           beat_s\n",
      "the             the  \n",
      "257             2_57 \n",
      "-               -    \n",
      "run             run  \n",
      "amount          amount\n",
      "by              by   \n",
      "which           which\n",
      "India           In_dia\n",
      "beat            beat \n",
      "Bermuda         Ber_mud_a\n",
      "in              in   \n",
      "Port            Port \n",
      "of              of   \n",
      "Spain           Spa_in\n",
      "in              in   \n",
      "2007            2007 \n",
      ",               ,    \n",
      "which           which\n",
      "was             wa_s \n",
      "equalled        equal_led\n",
      "five            five \n",
      "days            day_s\n",
      "ago             ago  \n",
      "by              by   \n",
      "South           South\n",
      "Africa          Africa\n",
      "in              in   \n",
      "their           t_heir\n",
      "victory         victor_y\n",
      "over            over \n",
      "West            West \n",
      "Indies          In_dies\n",
      "in              in   \n",
      "Sydney          Syd_ney\n",
      ".               .    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tok_file=/tmp/cricket.tok.txt\n",
    "polyglot --lang en morph --input $tok_file | tail -n 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nesting steps\n",
    "We can nest the tokenization and POS tagging in a simple bash pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which           which\r\n",
      "India           In_dia\r\n",
      "beat            beat \r\n",
      "Bermuda         Ber_mud_a\r\n",
      "in              in   \r\n",
      "Port            Port \r\n",
      "of              of   \r\n",
      "Spain           Spa_in\r\n",
      "in              in   \r\n",
      "2007            2007 \r\n",
      ",               ,    \r\n",
      "which           which\r\n",
      "was             wa_s \r\n",
      "equalled        equal_led\r\n",
      "five            five \r\n",
      "days            day_s\r\n",
      "ago             ago  \r\n",
      "by              by   \r\n",
      "South           South\r\n",
      "Africa          Africa\r\n",
      "in              in   \r\n",
      "their           t_heir\r\n",
      "victory         victor_y\r\n",
      "over            over \r\n",
      "West            West \r\n",
      "Indies          In_dies\r\n",
      "in              in   \r\n",
      "Sydney          Syd_ney\r\n",
      ".               .    \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot --lang en tokenize --input testdata/cricket.txt |  polyglot --lang en morph | tail -n 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation\n",
    "\n",
    "This work is a direct implementation of the research being described in the [Polyglot: Distributed Word Representations for Multilingual NLP](http://www.aclweb.org/anthology/W13-3520) paper.\n",
    "The author of this library strongly encourage you to cite the following paper if you are using this software."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. code-block::\n",
    "   @InProceedings{polyglot:2013:ACL-CoNLL,\n",
    "                Title:\tMorfessor 2.0: Python Implementation and Extensions for Morfessor Baseline\n",
    "                Author(s):\tVirpioja, Sami ; Smit, Peter ; Grönroos, Stig-Arne ; Kurimo, Mikko\n",
    "                Date:\t2013\n",
    "                Language:\ten\n",
    "                Pages:\t38\n",
    "                Department:\tSignaalinkäsittelyn ja akustiikan laitos\n",
    "                Department of Signal Processing and Acoustics\n",
    "                ISBN:\t978-952-60-5501-5 (electronic)\n",
    "                Series:\tAalto University publication series SCIENCE + TECHNOLOGY, 25/2013\n",
    "                ISSN:\t1799-490X (electronic)\n",
    "                1799-4896 (printed)\n",
    "                1799-4896 (ISSN-L)\n",
    "                Subject:\tComputer science, Linguistics\n",
    "                Keywords:\tmorpheme segmentation, morphology induction, unsupervised learning, semi-supervised learning, morfessor, machine learning\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Universal Part of Speech Tagging](http://universaldependencies.github.io/docs/u/pos/index.html)\n",
    "- [Universal Dependencies 1.0](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1464)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
